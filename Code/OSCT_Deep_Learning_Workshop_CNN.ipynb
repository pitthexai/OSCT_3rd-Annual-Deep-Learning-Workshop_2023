{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# OSCT Deep Learning Workshop_CNN: 2023"
      ],
      "metadata": {
        "id": "2FZMdWBjcpLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Case study: medical image segmentation"
      ],
      "metadata": {
        "id": "s2DOwkjQcr9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4ExHyXbycqV"
      },
      "outputs": [],
      "source": [
        "# Mounting google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-processing steps \n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "from itertools import chain\n",
        "from skimage.io import imread, imshow, concatenate_images, imread_collection\n",
        "\n",
        "\n",
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/KneeJointSpaceSegmentationDataset')\n",
        "!pwd\n",
        "img_dir = './Train_X/*.png'\n",
        "ground_dir=  './Train_Y/*.png'\n",
        "\n",
        "# Training images\n",
        "ground_image_set = imread_collection(ground_dir)\n",
        "ground_image_list = list(ground_image_set)\n",
        "\n",
        "train_image_set = imread_collection(img_dir)\n",
        "train_image_list = list(train_image_set)\n",
        "\n",
        "\n",
        "# Saving the images in list format for further processesing in training phase\n",
        "\n",
        "np.savez('data_train_list_apt.npz',train_image_list=train_image_list,ground_image_list=ground_image_list)\n",
        "\n"
      ],
      "metadata": {
        "id": "Ksxnjj8YZmLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import  cv2\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "import skimage\n",
        "#import scikit-image as skimage\n",
        "from itertools import chain\n",
        "from skimage.io import imread, imshow, concatenate_images, imread_collection\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score #, jaccard_similarity_score\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.backend import *\n",
        "from keras.models import *\n",
        "from numpy import load\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras import backend as keras\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "# GPU or CPU\n",
        "\n",
        "# with tf.device('/cpu:0'):\n",
        "with tf.device('/gpu:0'):\n",
        "\n",
        "\n",
        "    im_width=224\n",
        "    im_height=224\n",
        "\n",
        "## Loading train images list\n",
        "\n",
        "    data1= load('data_train_list_apt.npz')\n",
        "    train_image_list= data1['train_image_list']\n",
        "\n",
        "\n",
        "    X_list = []\n",
        "    for img in train_image_list:\n",
        "        img = img / 255\n",
        "        X_list.append(img)\n",
        "\n",
        "    X_array = np.asarray(X_list)\n",
        "    X_array = np.reshape(X_array, (X_array.shape[0], X_array.shape[1], X_array.shape[2], 1))\n",
        "\n",
        "    print(X_array.shape)\n",
        "\n",
        "\n",
        "## Loading ground/annotated images list\n",
        "\n",
        "   # data = load('data_list.npz', allow_pickle=True)\n",
        "    data = load ('data_train_list_apt.npz', allow_pickle=True)\n",
        "    ground_image_list = data['ground_image_list']\n",
        "\n",
        "    temp_ground = ground_image_list[0:40]\n",
        "\n",
        "\n",
        "    Y_list = []\n",
        "\n",
        "    for image in ground_image_list:\n",
        "        image = image[0:224, 0:224]                             ## Found some shape mismatches, thus resizing the images\n",
        "        if image.shape < (im_width, im_height):\n",
        "            image = np.resize(image, (im_width, im_height))\n",
        "        #  image= image.resize((224,224))\n",
        "\n",
        "        print(image.shape)\n",
        "        image = image / 255\n",
        "\n",
        "        Y_list.append(image)\n",
        "\n",
        "    Y_array = np.asarray(Y_list)\n",
        "\n",
        "    print(\"Shape fo y\", Y_array.shape)\n",
        "\n",
        "    Y_array = np.reshape(Y_array, (Y_array.shape[0], Y_array.shape[1], Y_array.shape[2], 1))\n",
        "\n",
        "    print(Y_array.shape)\n",
        "\n",
        "\n",
        "    ## U-net Architecture:\n",
        "\n",
        "\n",
        "    def conv2d_block(input_tensor,n_filters,kernel_size,batchnorm=True):\n",
        "        # first layer\n",
        "        x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
        "                   padding=\"same\")(input_tensor)\n",
        "        if batchnorm:\n",
        "            x = BatchNormalization()(x)\n",
        "        x = Activation(\"relu\")(x)\n",
        "        # second layer\n",
        "        x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
        "                   padding=\"same\")(x)\n",
        "        if batchnorm:\n",
        "            x = BatchNormalization()(x)\n",
        "        x = Activation(\"relu\")(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "    def get_unet(input_img, n_filters=16, dropout=0.5, batchnorm=True):\n",
        "        # contracting path\n",
        "\n",
        "        c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
        "        p1 = MaxPooling2D((2,2)) (c1)\n",
        "        p1 = Dropout(dropout*0.5)(p1)\n",
        "\n",
        "        c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
        "        p2 = MaxPooling2D((2,2)) (c2)\n",
        "        p2 = Dropout(dropout)(p2)\n",
        "\n",
        "        \n",
        "        c5 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
        "\n",
        "        # expansive path\n",
        "        u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)\n",
        "        u6 = concatenate([u6, c2])\n",
        "        u6 = Dropout(dropout)(u6)\n",
        "        c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
        "\n",
        "        u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)\n",
        "        u7 = concatenate([u7, c1])\n",
        "        u7 = Dropout(dropout)(u7)\n",
        "        c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
        "\n",
        "        outputs = Conv2D(1, (1, 1), activation='sigmoid') (c7)\n",
        "        model = Model(inputs=[input_img], outputs=[outputs])\n",
        "        return model\n",
        "\n",
        "\n",
        "    def data_split(matrix, target, test_proportion):\n",
        "        ratio = int(matrix.shape[0]/test_proportion)\n",
        "        X_train = matrix[ratio:,:,:]\n",
        "        X_test =  matrix[:ratio,:,:]\n",
        "        Y_train = target[ratio:,:,:]\n",
        "        Y_test =  target[:ratio,:,:]\n",
        "        return X_train, X_test, Y_train, Y_test\n",
        "\n",
        "\n",
        "    # Focal loss \n",
        "\n",
        "\n",
        "    def focal_loss(gamma=2., alpha=.25):\n",
        "        def focal_loss_fixed(y_true, y_pred):\n",
        "            pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
        "            pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
        "            return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
        "        return focal_loss_fixed\n",
        "\n",
        "\n",
        "    X_train,X_val,Y_train,Y_val=data_split(X_array,Y_array,3)\n",
        "    print (X_val.shape)\n",
        "    print (X_train.shape)\n",
        "\n",
        "    ## Model Executation\n",
        "\n",
        "    input_img = Input((im_width, im_height,1), name='img')\n",
        "    model = get_unet(input_img, n_filters=32, dropout=0.05, batchnorm=True)\n",
        "    model.compile(optimizer=Adam(),loss=[focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"])\n",
        "    model.summary()\n",
        "\n",
        "\n",
        "    ## Saving the best prediction moel(s)\n",
        "\n",
        "    callbacks = [\n",
        "        EarlyStopping(patience=10, verbose=1),\n",
        "        ReduceLROnPlateau(factor=0.1, patience=3, min_lr=0.00001, verbose=1),\n",
        "                 ModelCheckpoint('model-epoch100.h5', verbose=1, save_best_only=True, save_weights_only=True)      ## Best model gets saved as 'model-epoch100.h5'\n",
        "    ]\n",
        "\n",
        "\n",
        "    ## Testing the train images:\n",
        "\n",
        "    results = model.fit(X_train, Y_train, batch_size=8, epochs=10,callbacks=callbacks,\n",
        "                        validation_data=(X_val, Y_val))\n",
        "\n"
      ],
      "metadata": {
        "id": "HLSz5fLqbBwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import  cv2\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "import skimage\n",
        "#import scikit-image as skimage\n",
        "from itertools import chain\n",
        "from skimage.io import imread, imshow, concatenate_images, imread_collection\n",
        "from skimage. transform import resize\n",
        "from skimage.morphology import label\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score#, jaccard_similarity_score\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.backend import *\n",
        "from keras.models import *\n",
        "from numpy import load\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras import backend as keras\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "im_width = 224\n",
        "im_height = 224\n",
        "\n",
        "\n",
        "#data = load('data_list.npz')\n",
        "data = load('data_train_list_apt.npz')\n",
        "ground_image_list = data['ground_image_list']\n",
        "\n",
        "\n",
        "data2= load('data_train_list_apt.npz')\n",
        "\n",
        "\n",
        "train_image_list = data2['train_image_list']\n",
        "\n",
        "print (train_image_list[0].shape)\n",
        "print (ground_image_list[0].shape)\n",
        "\n",
        "X_list = []\n",
        "for img in train_image_list:\n",
        "    img = img / 255\n",
        "    X_list.append(img)\n",
        "\n",
        "X_array = np.asarray(X_list)\n",
        "X_array = np.reshape(X_array, (X_array.shape[0], X_array.shape[1], X_array.shape[2], 1))\n",
        "\n",
        "print(X_array.shape)\n",
        "\n",
        "\n",
        "data = load('data_train_list_apt.npz')\n",
        "ground_image_list = data['ground_image_list']\n",
        "\n",
        "\n",
        "Y_list = []\n",
        "\n",
        "for image in ground_image_list:\n",
        "    image = image[0:224, 0:224]\n",
        "    if image.shape < (im_width, im_height):\n",
        "        image = np.resize(image, (im_width, im_height))\n",
        "\n",
        "    #print(image.shape)\n",
        "    image = image / 255\n",
        "\n",
        "    Y_list.append(image)\n",
        "\n",
        "Y_array = np.asarray(Y_list)\n",
        "Y_array = np.reshape(Y_array, (Y_array.shape[0], Y_array.shape[1], Y_array.shape[2], 1))\n",
        "print(Y_array.shape)\n",
        "\n",
        "\n",
        "## Train Val Split\n",
        "\n",
        "def data_split(matrix, target, test_proportion):\n",
        "    ratio = int(matrix.shape[0] / test_proportion)\n",
        "    X_train = matrix[ratio:, :, :]\n",
        "    X_test = matrix[:ratio, :, :]\n",
        "    Y_train = target[ratio:, :, :]\n",
        "    Y_test = target[:ratio, :, :]\n",
        "    return X_train, X_test, Y_train, Y_test\n",
        "\n",
        "\n",
        "X_train,X_val,Y_train,Y_val=data_split(X_array,Y_array,3)\n",
        "\n",
        "print (\"=====================\")\n",
        "print (X_val.shape)\n",
        "print (X_train.shape)\n",
        "\n",
        "\n",
        "## U-net Architecture:\n",
        "\n",
        "\n",
        "def conv2d_block(input_tensor, n_filters, kernel_size, batchnorm=True):\n",
        "    # first layer\n",
        "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
        "               padding=\"same\")(input_tensor)\n",
        "    if batchnorm:\n",
        "        x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    # second layer\n",
        "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
        "               padding=\"same\")(x)\n",
        "    if batchnorm:\n",
        "        x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_unet(input_img, n_filters=16, dropout=0.5, batchnorm=True):\n",
        "    # contracting path\n",
        "\n",
        "    c1 = conv2d_block(input_img, n_filters=n_filters * 1, kernel_size=3, batchnorm=batchnorm)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "    p1 = Dropout(dropout * 0.5)(p1)\n",
        "\n",
        "    c2 = conv2d_block(p1, n_filters=n_filters * 2, kernel_size=3, batchnorm=batchnorm)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "    p2 = Dropout(dropout)(p2)\n",
        "\n",
        "\n",
        "    c5 = conv2d_block(p2, n_filters=n_filters * 4, kernel_size=3, batchnorm=batchnorm)\n",
        "\n",
        "    # expansive path\n",
        "    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = concatenate([u6, c2])\n",
        "    u6 = Dropout(dropout)(u6)\n",
        "    c6 = conv2d_block(u6, n_filters=n_filters * 8, kernel_size=3, batchnorm=batchnorm)\n",
        "\n",
        "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = concatenate([u7, c1])\n",
        "    u7 = Dropout(dropout)(u7)\n",
        "    c7 = conv2d_block(u7, n_filters=n_filters * 4, kernel_size=3, batchnorm=batchnorm)\n",
        "\n",
        "   \n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c7)\n",
        "    model = Model(inputs=[input_img], outputs=[outputs])\n",
        "    return model\n",
        "\n",
        "\n",
        "def data_split(matrix, target, test_proportion):\n",
        "    ratio = int(matrix.shape[0] / test_proportion)\n",
        "    X_train = matrix[ratio:, :, :]\n",
        "    X_test = matrix[:ratio, :, :]\n",
        "    Y_train = target[ratio:, :, :]\n",
        "    Y_test = target[:ratio, :, :]\n",
        "    return X_train, X_test, Y_train, Y_test\n",
        "\n",
        "\n",
        "## Code for focal loss ##\n",
        "\n",
        "\n",
        "def focal_loss(gamma=2., alpha=.25):\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
        "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
        "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) - K.sum(\n",
        "            (1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n",
        "\n",
        "    return focal_loss_fixed\n",
        "\n",
        "\n",
        "X_train, X_val, Y_train, Y_val = data_split(X_array, Y_array, 3)\n",
        "print(X_val.shape)\n",
        "print(X_train[0].shape)\n",
        "\n",
        "\n",
        "\n",
        "input_img = Input((im_width, im_height,1), name='img')\n",
        "model = get_unet(input_img, n_filters=32, dropout=0.05, batchnorm=True)\n",
        "model.compile(optimizer=Adam(), loss=[focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "\n",
        "model.load_weights('model-epoch100.h5')\n",
        "\n",
        "pred_val = model.predict(X_val,verbose=1)\n",
        "print (type(pred_val))\n",
        "#np.savez('model_results.npz',preds_val= pred_val, preds_train=preds_train)\n",
        "pred_train= model.predict(X_train,verbose=1)\n",
        "\n",
        "print (\"predicted!\")\n",
        "\n",
        "np.savez('results.npz',preds_val= pred_val, preds_train=pred_train, X_train= X_train, Y_train=Y_train, X_val= X_val, Y_val= Y_val)\n",
        "\n"
      ],
      "metadata": {
        "id": "vq2xPyJt11lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving files and image visualization\n",
        "\n",
        "import numpy as np\n",
        "from numpy import load\n",
        "import matplotlib\n",
        "import scipy\n",
        "import imageio\n",
        "\n",
        "\n",
        "data= load('results.npz')\n",
        "#preds_val=data['preds_val']\n",
        "preds_train= data['preds_train']\n",
        "\n",
        "\n",
        "print ('loaded')\n",
        "\n",
        "os.chdir('/content/gdrive/My Drive/KneeJointSpaceSegmentationDataset')\n",
        "\n",
        "num= 0\n",
        "\n",
        "for img in preds_train:\n",
        "    img[img > 0.3] = 1\n",
        "    img= np.squeeze(img)\n",
        "    imageio.imwrite('./results/pred_train/ '+str(num) +'.png', img)\n",
        "    num +=1\n",
        "\n",
        "\n",
        "print ('done!')\n",
        "\n",
        "flag=0\n",
        "\n",
        "for img in X_train:\n",
        "    img = np.squeeze(img)\n",
        "    imageio.imwrite('./results/X_train/ ' + str(flag) + '.png', img)\n",
        "    flag += 1\n",
        "\n",
        "print ('done!')\n",
        "temp= 0\n",
        "\n",
        "for img in Y_train:\n",
        "    img = np.squeeze(img)\n",
        "    imageio.imwrite('./results/Y_train/ ' + str(temp) + '.png', img)\n",
        "    temp += 1\n",
        "\n",
        "\n",
        "print ('done!')\n",
        "cal= 0\n",
        "\n",
        "for img in Y_val:\n",
        "    img = np.squeeze(img)\n",
        "    imageio.imwrite('./results/Y_val/ ' + str(cal) + '.png', img)\n",
        "    cal += 1\n",
        "\n",
        "print ('done!')\n",
        "\n",
        "j= 0\n",
        "\n",
        "for img in X_val:\n",
        "    imageio.imwrite('./results/X_val/ ' + str(j) + '.png', img)\n",
        "    j += 1\n",
        "\n",
        "print ('done!')"
      ],
      "metadata": {
        "id": "KPpJJ-X-apSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating Intersection over Union (IoU)\n",
        "\n",
        "#import scikit-learn as sklearn\n",
        "import cv2\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import jaccard_score\n",
        "\n",
        "os.chdir('/content/gdrive/My Drive/KneeJointSpaceSegmentationDataset')\n",
        "\n",
        "ground_dir= './results/Y_val/ 27.png'\n",
        "\n",
        "ground_img= im = plt.imread(ground_dir)\n",
        "print (type(ground_img))\n",
        "print (ground_img.shape)\n",
        "\n",
        "pred_dir  ='./results/pred_train/ 27.png'\n",
        "\n",
        "pred_img=  plt.imread(pred_dir)\n",
        "\n",
        "IOU_score = jaccard_score(np.round(ground_img), np.round(pred_img), average='micro')\n",
        "\n",
        "print (IOU_score)"
      ],
      "metadata": {
        "id": "1uA4ewEUhetE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}